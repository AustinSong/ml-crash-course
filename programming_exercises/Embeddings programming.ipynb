{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Sparse Data and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot \n",
    "import collections\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "\n",
    "jtplot.style()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "train_url = 'https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
    "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
    "test_url = 'https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
    "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(record):\n",
    "    \"\"\"\n",
    "    Extracts feature and labels.\n",
    "    \n",
    "    Args:\n",
    "        record: File path to TFRecord file\n",
    "    Returns:\n",
    "        A 'tuple' '(labels, featuers)':\n",
    "            labels: Tensor with corresponding labels\n",
    "            features: Dict of tensors representing the features\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths,\n",
    "        \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "    }\n",
    "    \n",
    "    parsed_features = tf.parse_single_example(record, features)\n",
    "    \n",
    "    terms = parsed_features['terms'].values\n",
    "    labels = parsed_features['labels']\n",
    "    \n",
    "    return {'terms':terms}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ({terms: (?,)}, (1,)), types: ({terms: tf.string}, tf.float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create DataSet object\n",
    "ds = tf.data.TFRecordDataset(train_path)\n",
    "# map features and labels with parse function\n",
    "ds = ds.map(_parse_function)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'terms': array([b'but', b'it', b'does', b'have', b'some', b'good', b'action',\n",
       "         b'and', b'a', b'plot', b'that', b'is', b'somewhat', b'interesting',\n",
       "         b'.', b'nevsky', b'acts', b'like', b'a', b'body', b'builder',\n",
       "         b'and', b'he', b'isn', b\"'\", b't', b'all', b'that', b'attractive',\n",
       "         b',', b'in', b'fact', b',', b'imo', b',', b'he', b'is', b'ugly',\n",
       "         b'.', b'(', b'his', b'acting', b'skills', b'lack', b'everything',\n",
       "         b'!', b')', b'sascha', b'is', b'played', b'very', b'well', b'by',\n",
       "         b'joanna', b'pacula', b',', b'but', b'she', b'needed', b'more',\n",
       "         b'lines', b'than', b'she', b'was', b'given', b',', b'her',\n",
       "         b'character', b'needed', b'to', b'be', b'developed', b'.',\n",
       "         b'there', b'are', b'way', b'too', b'many', b'men', b'in', b'this',\n",
       "         b'story', b',', b'there', b'is', b'zero', b'romance', b',', b'too',\n",
       "         b'much', b'action', b',', b'and', b'way', b'too', b'dumb', b'of',\n",
       "         b'an', b'ending', b'.', b'it', b'is', b'very', b'violent', b'.',\n",
       "         b'i', b'did', b'however', b'love', b'the', b'scenery', b',',\n",
       "         b'this', b'movie', b'takes', b'you', b'all', b'over', b'the',\n",
       "         b'world', b',', b'and', b'that', b'is', b'a', b'bonus', b'.', b'i',\n",
       "         b'also', b'liked', b'how', b'it', b'had', b'some', b'stuff',\n",
       "         b'about', b'the', b'mafia', b'in', b'it', b',', b'not', b'too',\n",
       "         b'much', b'or', b'too', b'little', b',', b'but', b'enough',\n",
       "         b'that', b'it', b'got', b'my', b'attention', b'.', b'the',\n",
       "         b'actors', b'needed', b'to', b'be', b'more', b'handsome', b'.',\n",
       "         b'.', b'.', b'the', b'biggest', b'problem', b'i', b'had', b'was',\n",
       "         b'that', b'nevsky', b'was', b'just', b'too', b'normal', b',',\n",
       "         b'not', b'sexy', b'enough', b'.', b'i', b'think', b'for', b'most',\n",
       "         b'guys', b',', b'sascha', b'will', b'be', b'hot', b'enough', b',',\n",
       "         b'but', b'for', b'us', b'ladies', b'that', b'are', b'fans', b'of',\n",
       "         b'action', b',', b'nevsky', b'just', b'doesn', b\"'\", b't', b'cut',\n",
       "         b'it', b'.', b'overall', b',', b'this', b'movie', b'was', b'fine',\n",
       "         b',', b'i', b'didn', b\"'\", b't', b'love', b'it', b'nor', b'did',\n",
       "         b'i', b'hate', b'it', b',', b'just', b'found', b'it', b'to', b'be',\n",
       "         b'another', b'normal', b'action', b'flick', b'.'], dtype=object)},\n",
       " array([0.], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = ds.make_one_shot_iterator().get_next()\n",
    "sess = tf.Session()\n",
    "sess.run(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input_fn that parses the tf.Examples from the given files, \n",
    "# and split them into features and targets\n",
    "def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(input_filenames)\n",
    "    ds = ds.map(_parse_function)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "        \n",
    "    # our feature data is variable-length, so we pad and batch\n",
    "    # each field of the dataset structure to whatever size is necessary\n",
    "    ds = ds.padded_batch(25, ds.output_shapes)\n",
    "    ds = ds.repeat(num_epochs)\n",
    "    \n",
    "    # return next batch\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Use a Linear  Model with Sparse Inputs and an Explicit Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 informative terms that compose our model vocabulary \n",
    "informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n",
    "                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n",
    "                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n",
    "                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n",
    "                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n",
    "                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n",
    "                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n",
    "                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n",
    "                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n",
    "                     \"drama\", \"family\")\n",
    "\n",
    "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set metrics:\n",
      "accuracy 0.78904\n",
      "accuracy_baseline 0.5\n",
      "auc 0.8723858\n",
      "auc_precision_recall 0.8633868\n",
      "average_loss 0.45013484\n",
      "label/mean 0.5\n",
      "loss 11.253371\n",
      "prediction/mean 0.509017\n",
      "global_step 1000\n",
      "---\n",
      "Test set metrics:\n",
      "accuracy 0.785\n",
      "accuracy_baseline 0.5\n",
      "auc 0.86992747\n",
      "auc_precision_recall 0.8604129\n",
      "average_loss 0.4518627\n",
      "label/mean 0.5\n",
      "loss 11.296567\n",
      "prediction/mean 0.5075821\n",
      "global_step 1000\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "feature_columns = [terms_feature_column]\n",
    "\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=my_optimizer)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: _input_fn([train_path]),\n",
    "    steps=1000)\n",
    "\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "    input_fn=lambda: _input_fn([train_path]),\n",
    "    steps=1000)\n",
    "print(\"Training set metrics:\")\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print(\"---\")\n",
    "\n",
    "print(\"Test set metrics:\")\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "    input_fn=lambda: _input_fn([test_path]),\n",
    "    steps=1000)\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Use a Deep Neural Network (DNN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set metrics:\n",
      "accuracy 0.78748\n",
      "accuracy_baseline 0.5\n",
      "auc 0.87328154\n",
      "auc_precision_recall 0.8660304\n",
      "average_loss 0.4458464\n",
      "label/mean 0.5\n",
      "loss 11.14616\n",
      "prediction/mean 0.48554677\n",
      "global_step 1000\n",
      "---\n",
      "Test set metrics:\n",
      "accuracy 0.78172\n",
      "accuracy_baseline 0.5\n",
      "auc 0.8703055\n",
      "auc_precision_recall 0.86240315\n",
      "average_loss 0.44941112\n",
      "label/mean 0.5\n",
      "loss 11.235278\n",
      "prediction/mean 0.48477292\n",
      "global_step 1000\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=[tf.feature_column.indicator_column(terms_feature_column)],\n",
    "    hidden_units=[20,20],\n",
    "    optimizer=my_optimizer)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: _input_fn([train_path]),\n",
    "    steps=1000)\n",
    "\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "    input_fn=lambda: _input_fn([train_path]),\n",
    "    steps=1000)\n",
    "print(\"Training set metrics:\")\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print(\"---\")\n",
    "\n",
    "print(\"Test set metrics:\")\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "    input_fn=lambda: _input_fn([test_path]),\n",
    "    steps=1000)\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Use an Embedding with a DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set metrics:\n",
      "accuracy 0.7814\n",
      "accuracy_baseline 0.5\n",
      "auc 0.8696148\n",
      "auc_precision_recall 0.8583567\n",
      "average_loss 0.45862216\n",
      "label/mean 0.5\n",
      "loss 11.465553\n",
      "prediction/mean 0.5454261\n",
      "global_step 1000\n",
      "---\n",
      "Test set metrics:\n",
      "accuracy 0.78192\n",
      "accuracy_baseline 0.5\n",
      "auc 0.8694579\n",
      "auc_precision_recall 0.85788834\n",
      "average_loss 0.45839965\n",
      "label/mean 0.5\n",
      "loss 11.459991\n",
      "prediction/mean 0.5444817\n",
      "global_step 1000\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=[tf.feature_column.embedding_column(terms_feature_column, 2)],\n",
    "    hidden_units=[20,20],\n",
    "    optimizer=my_optimizer)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: _input_fn([train_path]),\n",
    "    steps=1000)\n",
    "\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "    input_fn=lambda: _input_fn([train_path]),\n",
    "    steps=1000)\n",
    "print(\"Training set metrics:\")\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print(\"---\")\n",
    "\n",
    "print(\"Test set metrics:\")\n",
    "evaluation_metrics = classifier.evaluate(\n",
    "    input_fn=lambda: _input_fn([test_path]),\n",
    "    steps=1000)\n",
    "for m in evaluation_metrics:\n",
    "    print(m, evaluation_metrics[m])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
